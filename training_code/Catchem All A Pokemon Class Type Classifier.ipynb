{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“We have adhered to all tenants of the Duke Community Standard in the completion of this assignment.”- Marc Chmielewski, Andrew Sander, Yi Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the game Pokemon, there are discrete categories of Pokemon combatants. These categories are called types and generally represented by the physical attributes of the pokemon. Said attributes often include color, body features, and accessories. A player can have an advantage or disadvantage in the game depending on what type of Pokemon they have in battle. A Pokemon whose type is super-effective against an opposing Pokemon is more likely to win a game than the other Pokemon that is weak to that type. It is important, then, for a player to be able to classify which type of Pokemon they have and that they are facing as soon as possible. A convolutional neural network (CNN) that could determine a Pokemon’s type based on the image of the creature as input would be a huge asset to the player, especially in a competitive tournament environment. \n",
    "\n",
    "The main question that we are asking is what attributes of a Pokemon’s appearance contribute to its type label, and how much each of those attributes matter in determining the type. We hypothesize that the color palettes of the images will contribute most to classification, followed closely by combinations of geometrical shapes such as flames and plants. The presence or absence of curvatures or sharp points can also play a role in classification. To those who are unfamiliar with Pokemon, this project would be interesting in its ability to detect both subtle and hidden patterns in artwork and categorize that artwork based on those patterns. This process could be used by art students, for example, to sift through a large database of images and find objects that have certain attributes that are interesting to them.\n",
    "\n",
    "## Prior Research\n",
    "A generative adversarial network (GAN) was created a couple of years ago that generated new Pokemon based on a database of preexisting Pokemon. (The data can be found here and the Git repository here). Though this attempt was unsuccessful, largely due to the small amount of training data that the developer used, a network that is simply classifying Pokemon testing data as opposed to generating new data will likely be much more feasible. \n",
    "\n",
    "Previous type classifiers have been made using characteristics of the Pokemon other than physical appearance. A model with a similar goal is linked here. This model attempts to predict the type of a Pokemon based on numerical gameplay attributes; primarily battle statistics and physical attributes (attack, defense, speed, weight etc). Our model is unique in that it will be determining the type solely with regards to the target Pokemon's physical appearance. In other words, this model’s classification procedure will be driven exclusively by image composition and coloration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "A dataset of 813 images of Pokemon was acquired from the previously mentioned GAN project. All of the sourced images are 256x256 pixels, of type .jpg, and have white backgrounds. Additionally, some Pokemon are represented in different positions/different art styles as a result of an in-game mechanic called Mega Evolution. Because these data points are compositional outliers, that is, they vary substantially from the otherwise relatively consistent standards of image color and structure, the team initially considered discarding these data points. However, given the relative sparsity of the data, we elected that they should be kept in. Given that the team is utilizing a supervised approach to the classification question, the data were subsequently labeled according to their types. There are 18 total types of Pokemon, and a histogram of the distribution of types is depicted below.\n",
    "\n",
    "[Somehow insert an image into this notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "PATH = os.getcwd()\n",
    "\n",
    "# ----------------------------Packages below are Keras-specific-------------------------------------------\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Due to the sparsity of the base dataset, it became immediately apparent that the team would need to augment it with additional images of Pokemon. However, there has been a large amount of variation in how Pokemon have been depicted in the media over time. For example, between Generations V and VI, the main-series games made the jump from 2D to 3D for the first time, and with this transition came a total rework of the library of Pokemon sprites. While we as humans can still easily tell that the two Pokemon in the figures below are both Squirtles, it’s logical to assume that an ML algorithm may have a harder time doing so. Thus, the team opted to restrict themselves to the traditional 2D depictions of Pokemon often seen in the anime and other promotional materials. \n",
    "\n",
    "## Train, Test, and Validation Set Division\n",
    "Before implementing a machine learning model, it was also necessary to sort the dataset into training, validation, and testing datasets. The training set contained 70% of the total data, validation contained 10%, and testing 20%. It was important to make sure the data was stratified, that is the same ratio amongst types should appear across all three data sets. This ensured that the training model would not overfit to a specific type of Pokemon and test with types it had never seen before. A script was written to take the entire data set (both base and augmented images) and sort them into various training, validation, and testing sets; the type distributions are constant across the three sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Array Preparation\n",
    "The images needed to be converted into numpy matrices in order to be processed by the neural network. We read the images in as a matrix of pixel values and normalized them between 0 and 1. Then, we resized the images so that they are 50x50 pixels. Therefore, the 3D matrix for each image, including color channels, is 50x50x3. Finally, we created a 4D matrix with the dimensions (number of images)x50x50x3, and we repeated for training, testing, and validation datasets. \n",
    "\n",
    "## Label Array Preparation\n",
    "We created a dictionary where keys are filenames and values are integer representations of the 18 Pokemon types. Therefore, every time an image is processed its label is added to the vector. This was also repeated for training, testing, and validation datasets. \n",
    "\n",
    "All numpy arrays created are then saved to our disk as .npy files. They are loaded below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 5784 images, testing set: 1633 images, validation set: 815 images\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(\"xtrain.npy\")\n",
    "y_train = np.load(\"ytrain.npy\")\n",
    "x_test = np.load(\"xtest.npy\")\n",
    "y_test = np.load(\"ytest.npy\")\n",
    "x_valid = np.load(\"xvalidation.npy\")\n",
    "y_valid = np.load(\"yvalidation.npy\")\n",
    "print(\"Training set: {} images, testing set: {} images, validation set: {} images\".\n",
    "      format(len(y_train), len(y_test), len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5784, 50, 50, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a visualization of one of the train images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(False)\n",
    "plt.imshow(x_train[0])\n",
    "plt.xlabel(\"Label: Psychic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below converts our labels to categorical form, which Keras uses to train models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes = 18)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes = 18)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the CNN\n",
    "Due to the fact that this is a classification task and the data is image-based, the team opted to utilize a convolutional neural network (CNN) to develop the ML model. A CNN is optimal for this task as the data has many more features than a simple multi-layer perceptron could reasonably ascertain. Furthermore, unlike the individual Multi-layer Perceptrons (MLPs), CNN’s are capable of parsing images with RGB-color channel information as n1 x n2  x 3-dimensional vectors. Given that the primary features that the model used to classify the images were based on color and composition, the fact that CNN’s can handle color is invaluable. \n",
    "\n",
    "The model training was performed using the Keras package from TensorFlow. The hypermarameters below are determined to yield the best results after a few training attempts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 18\n",
    "epochs = 150\n",
    "num_predictions = 20\n",
    "batch_size = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'pokemonModel.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=(50, 50, 3), \n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(18, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "                        \n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that we trained was saved to the working directory, and is loaded below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel = load_model(os.path.join(os.getcwd(), 'saved_models/pokemonModel.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.95582825\n"
     ]
    }
   ],
   "source": [
    "scores = savedModel.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for 150 epochs, the model performed very well on the testing and validation sets.\n",
    "The model achieved 96% accuracy with images in the validation set. The accuracy of the model on the training and testing sets (shown as the validation data in the figures below). While the model had success on the testing and validation sets, the model falls short on classifying Pokemon of differing orientation from that in the training set. For example, see the two examples of Lugia below. The image to the left is the image that the model used to train, and the image to the right is one not included in the dataset. The second image was classified incorrectly, showing that model does not do well with classifying images of differing orientation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Overall, the model was generally successful at classifying Pokemon, and was even successful in classifying several novel Pokemon from the release of Pokemon Sword and Shield in November of 2019. A notable deficit was observed in the classification of dragon type Pokemon, which can be largely attributed to their diverse coloration and overall form factor. Additionally, the model often struggled with Pokemon that were in some way non-linearly transformed from their training images. This was often caused by the Pokemon adopting a different pose or posture but could also be attributed to alternative forms of depiction. Finally, some multi-type Pokemon, such as Scrafty, were erroneously categorized into their “secondary” type, which while not inaccurate, was not the intended behavior of the model. \n",
    "\n",
    "Future iterations of the model will likely include additional training layers to permit for the uptake of additional latent features within the data, utilize Keras’ in-built real-time data augmentation features to dynamically improve the dataset, and utilize more training echelons to increase the overall resolution of the hidden-layer filters. All three of these changes should improve the model’s capability to classify these oft-misclassified Pokemon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
